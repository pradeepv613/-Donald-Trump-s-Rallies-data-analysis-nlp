{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#read data\nspeechs = list()\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        file_path = os.path.join(dirname, filename)\n        print(file_path)\n        text = open(file_path,'r').read()\n        speechs.append(text)\n\nprint(f\"Total Number of Documents : {len(speechs)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"speechs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import FreqDist\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"speeches=str(speechs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import words as english_words, stopwords\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=re.sub('\\n', ' ',speeches).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=re.sub('\\r', '',speeches).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=re.sub(' ', '',speeches).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=re.sub('[^a-zA-Z \\n]', '', speeches)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word=words.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \n  \nstop_words = set(stopwords.words('english')) \n#stop_words = set(w.lower() for w in stopwords.words())\n#print(stop_words)\nword_tokens = word_tokenize(word) \n  \nfiltered_sentence = [w for w in word_tokens if not w in stop_words] \nprint(filtered_sentence) \n  \n''''filtered_sentence = [] \n  \nfor w in word_tokens: \n    if w not in stop_words: \n        filtered_sentence.append(w) \n  \n#print(word_tokens) \nprint(filtered_sentence) \n\n\n#preprocessed_speechs = list(map(cleansing_text, speechs))'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import FreqDist\nword_frequency = FreqDist(filtered_sentence)# write your code here\n\n# extract the frequency of third most frequent word\nfreq = word_frequency.most_common(10)\nprint(freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"listToStr = ' '.join([str(elem) for elem in filtered_sentence]) \n  \nprint(listToStr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#listToStr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import PorterStemmer\nporter = PorterStemmer()\ndef stemSentence(sentence):\n    token_words=word_tokenize(sentence)\n    token_words\n    stem_sentence=[]\n    for word in token_words:\n        stem_sentence.append(porter.stem(word))\n        stem_sentence.append(\" \")\n    return \"\".join(stem_sentence)\n\nx=stemSentence(listToStr)\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import FreqDist\ny=word_tokenize(x)\nword_frequency = FreqDist(y)# write your code here\n\n# extract the frequency of third most frequent word\nfreq = word_frequency.most_common()\nprint(freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS \nimport matplotlib.pyplot as plt\n\n\nwordcloud = WordCloud(width = 800, height = 800,background_color ='grey', min_font_size = 10).generate(x)\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.rcParams.update({'font.size': 25})\nplt.axis(\"off\") \nplt.title('Word Cloud: Donald JTrump Rallies ')\nplt.tight_layout(pad = 0) \n  \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nimport seaborn as sns\nfrom nltk import FreqDist\ny=word_tokenize(x)\nword_frequency = FreqDist(y)# write your code here\n\n# extract the frequency of third most frequent word\n#word_freq_count = Counter(' '.join(freq).split(\",\"))\n\ncommon_words = [word[0] for word in word_frequency.most_common(20)]\ncommon_counts = [word[1] for word in word_frequency.most_common(20)]\n\nplt.figure(figsize=(15, 12))\n\nsns.set_style(\"whitegrid\")\nsns_bar = sns.barplot(x=common_words, y=common_counts)\nsns_bar.set_xticklabels(common_words, rotation=45)\nplt.title('Most Common Words in the document')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import islice\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n\ntfidf_vec = TfidfVectorizer(stop_words=\"english\")\ntransformed = tfidf_vec.fit_transform(raw_documents=speechs)\nindex_value={i[1]:i[0] for i in tfidf_vec.vocabulary_.items()}\nprint( {k: index_value[k] for k in list(index_value)[:50]})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nstop_words.extend(['from', 'subject', 're', 'edu', 'use','ell'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stop_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#stop_words = set(w.lower() for w in stopwords.words())\n#print(stop_words)\nword_tokens = word_tokenize(word) \n  \nfiltered_sentence = [w for w in word_tokens if not w in stop_words and len(w) > 3 ] \nprint(filtered_sentence) \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_words = len(list(set(filtered_sentence)))\ntotal_words\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_words_list = list(set(filtered_sentence))\nprint(total_words_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df=pd.DataFrame([x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['stopwords_removal']=filtered_sentence\nlistToStr2 = ' '.join([str(elem) for elem in filtered_sentence]) \n  \nprint(listToStr2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS \nimport matplotlib.pyplot as plt\n\nwordcloud = WordCloud(width = 800, height = 800,background_color ='grey', min_font_size = 10).generate(listToStr2)\n\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.rcParams.update({'font.size': 25})\nplt.axis(\"off\") \nplt.title('Word Cloud: Donald JTrump Rallies ')\nplt.tight_layout(pad = 0) \n  \nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}